name: Website Grammar Check (GPT-5 w/ fallback)

on:
  repository_dispatch:
    types: [grammar-check]
  workflow_dispatch:
    inputs:
      url:
        description: "URL to check (optional if payload supplies it)"
        required: false
        type: string
      text:
        description: "Raw text to check (optional)"
        required: false
        type: string

permissions:
  contents: read
  issues: write

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y jq lynx perl

      - name: Extract payload and build FULL text
        id: build
        run: |
          set -euo pipefail
          URL=$(jq -r '.client_payload.url // empty' "$GITHUB_EVENT_PATH")
          TEXT=$(jq -r '.client_payload.text // empty' "$GITHUB_EVENT_PATH")
          CID=$(jq -r '.client_payload.client_id // empty' "$GITHUB_EVENT_PATH")
          if [ -z "$URL" ];  then URL="${{ github.event.inputs.url }}";  fi
          if [ -z "$TEXT" ]; then TEXT="${{ github.event.inputs.text }}"; fi

          echo "SRC_URL=$URL"   >> $GITHUB_ENV
          echo "CLIENT_ID=$CID" >> $GITHUB_ENV

          if [ -n "$URL" ]; then
            echo "Fetching $URL"
            curl -fsSL -H "User-Agent: Mozilla/5.0" "$URL" -o page.html
            lynx -dump -nolist page.html > doc_full.txt
          else
            printf "%s" "$TEXT" > doc_full.txt
          fi

          if [ ! -s doc_full.txt ]; then
            echo "::error::No content to analyze (neither URL nor text)"; exit 1
          fi

          BYTES=$(wc -c < doc_full.txt)
          echo "FULL_BYTES=$BYTES" >> $GITHUB_ENV
          echo "Built doc_full.txt ($BYTES bytes)"

      - name: Chunk long text (~15 KB per chunk)
        run: |
          set -euo pipefail
          rm -rf chunks reports
          mkdir -p chunks reports
          # 15,000 bytes keeps requests small & safe
          split -b 15000 -d -a 3 doc_full.txt chunks/chunk_
          COUNT=$(ls chunks | wc -l | tr -d ' ')
          echo "CHUNK_COUNT=$COUNT" >> $GITHUB_ENV
          echo "Created $COUNT chunk(s)"

      - name: Run GPT proofreading on all chunks (try gpt-5, fallback to gpt-4o)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: ${{ vars.OPENAI_MODEL }}   # optional override
        run: |
          set -euo pipefail
          if [ -z "${OPENAI_API_KEY:-}" ]; then
            echo "::error::OPENAI_API_KEY secret is not set"; exit 1
          fi
          PRIMARY_MODEL="${OPENAI_MODEL:-gpt-5}"
          FALLBACK_MODEL="gpt-4o"

          for f in $(ls chunks | sort); do
            fp="chunks/$f"
            echo "Checking $fp (primary: $PRIMARY_MODEL, fallback: $FALLBACK_MODEL)"

            try_model() {
              local MODEL="$1"
              jq -Rs --arg model "$MODEL" '{
                model: $model,
                response_format: { "type": "json_object" },
                messages: [
                  {"role":"system","content":"You are a strict copy editor. Given TEXT, list EVERY spelling, grammar, punctuation, agreement, or style mistake. Output ONLY valid JSON: {\"matches\":[{\"rule\":\"Spelling|Grammar|Punctuation|Agreement|Style\",\"message\":\"what is wrong\",\"context\":\"short snippet around the error\",\"suggestion\":\"best single replacement or null\"}],\"chunk_bytes\":0}. Do not include explanations outside JSON."},
                  {"role":"user","content": ("TEXT:\\n\\n" + .)}
                ],
                temperature: 0,
                max_tokens: 4000
              }' "$fp" > req.json

              curl -sS -o out.json -w "%{http_code}" \
                -X POST https://api.openai.com/v1/cha
