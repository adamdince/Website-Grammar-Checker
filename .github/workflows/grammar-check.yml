name: Website Grammar Check

on:
  repository_dispatch:
    types: [grammar-check]
  workflow_dispatch:
    inputs:
      url:
        description: "URL to check (optional if payload supplies it)"
        required: false
        type: string
      text:
        description: "Raw text to check (optional)"
        required: false
        type: string

permissions:
  contents: read
  issues: write

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y jq lynx

      - name: Extract payload and build FULL text
        id: build
        run: |
          set -euo pipefail
          URL=$(jq -r '.client_payload.url // empty' "$GITHUB_EVENT_PATH")
          TEXT=$(jq -r '.client_payload.text // empty' "$GITHUB_EVENT_PATH")
          CID=$(jq -r '.client_payload.client_id // empty' "$GITHUB_EVENT_PATH")
          # allow manual run inputs too
          if [ -z "$URL" ];  then URL="${{ github.event.inputs.url }}";  fi
          if [ -z "$TEXT" ]; then TEXT="${{ github.event.inputs.text }}"; fi

          echo "SRC_URL=$URL"   >> $GITHUB_ENV
          echo "CLIENT_ID=$CID" >> $GITHUB_ENV

          if [ -n "$URL" ]; then
            echo "Fetching $URL"
            curl -fsSL -H "User-Agent: Mozilla/5.0" "$URL" -o page.html
            lynx -dump -nolist page.html > doc_full.txt
          else
            printf "%s" "$TEXT" > doc_full.txt
          fi

          if [ ! -s doc_full.txt ]; then
            echo "::error::No content to analyze (neither URL nor text)"; exit 1
          fi

          BYTES=$(wc -c < doc_full.txt)
          echo "FULL_BYTES=$BYTES" >> $GITHUB_ENV
          echo "Built doc_full.txt ($BYTES bytes)"

      - name: Chunk long text (~15 KB per chunk)
        run: |
          set -euo pipefail
          rm -rf chunks reports
          mkdir -p chunks reports
          # Split by bytes for robustness; 15000 stays within LT public limits
          split -b 15000 -d -a 3 doc_full.txt chunks/chunk_
          COUNT=$(ls chunks | wc -l | tr -d ' ')
          echo "CHUNK_COUNT=$COUNT" >> $GITHUB_ENV
          echo "Created $COUNT chunk(s)"

      - name: Run LanguageTool on all chunks
        run: |
          set -euo pipefail
          for f in $(ls chunks | sort); do
            fp="chunks/$f"
            echo "Checking $fp"
            HTTP=$(curl -sS -o "reports/$f.json" -w "%{http_code}" \
              -X POST https://api.languagetool.org/v2/check \
              -H 'Content-Type: application/x-www-form-urlencoded' \
              -d 'language=en-US' \
              --data-urlencode text@"$fp")
            if [ "$HTTP" -ne 200 ]; then
              echo "::warning::LanguageTool returned $HTTP for $fp (using empty matches)"
              echo '{"matches":[]}' > "reports/$f.json"
            else
              if ! jq -e . "reports/$f.json" >/dev/null 2>&1; then
                echo "::warning::Non-JSON from LanguageTool for $fp (using empty matches)"
                echo '{"matches":[]}' > "reports/$f.json"
              fi
            fi
            sleep 1  # gentle throttle for the public API
          done

          # Aggregate all matches across chunks
          jq -s '[.[] | .matches] | flatten' reports/*.json > matches_all.json
          COUNT=$(jq 'length' matches_all.json)
          echo "COUNT=$COUNT" >> $GITHUB_ENV
          echo "Aggregated $COUNT match(es)"

      - name: Build Markdown report
        run: |
          {
            echo "# Grammar Report"
            if [ -n "${SRC_URL}"   ]; then echo "**URL:** ${SRC_URL}  "; fi
            if [ -n "${CLIENT_ID}" ]; then echo "**Client ID:** ${CLIENT_ID}  "; fi
            echo "**Bytes scanned (full):** ${FULL_BYTES}  "
            echo "**Chunks:** ${CHUNK_COUNT}  "
            echo "**Issues found:** ${COUNT}"
            echo
            echo "## Top findings"
            jq -r '
              .[0:100][] |
              "- **\(.rule.issueType // .rule.category.id // .rule.id)**: \(.message)
                 - Context: \"\(.context.text)\"
                 - Suggestion: \((.replacements[0].value // "—"))"
            ' matches_all.json
          } > report.md
          echo "Report written to report.md"

      - name: Create issue with report
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const url = process.env.SRC_URL || '(manual input)';
            const title = `Grammar report – ${url} – ${new Date().toISOString().slice(0,19)}Z`;
            const body  = fs.readFileSync('report.md','utf8');
            const labels = ['grammar-report'];
            const { data: issue } = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title, body, labels
            });
            core.info(`Created issue #${issue.number}`);

      # ---- Send ALL findings to Google Doc via POST (requires doPost in your Web App) ----
      - name: Post ALL findings to Google Doc (optional)
        env:
          DOC_CALLBACK_URL: ${{ secrets.DOC_CALLBACK_URL }}   # must be your Web App /exec URL
          DOC_CALLBACK_KEY: ${{ secrets.DOC_CALLBACK_KEY }}   # must match IMPORT_API_KEY in Apps Script
          SRC_URL:    ${{ env.SRC_URL }}
          CLIENT_ID:  ${{ env.CLIENT_ID }}
          COUNT:      ${{ env.COUNT }}
        run: |
          set -euo pipefail

          echo "Using callback endpoint: ${DOC_CALLBACK_URL:-<unset>}"

          if [ -z "${DOC_CALLBACK_URL:-}" ] || [ -z "${DOC_CALLBACK_KEY:-}" ]; then
            echo "Doc callback secrets not set; skipping."
            exit 0
          fi

          # Build ALL matches (compact, but includes every finding)
          jq '[ .[] | {
                rule:(.rule.issueType // .rule.category.id // .rule.id),
                message:.message,
                context:(.context.text),
                suggestion:(.replacements[0].value // null)
              } ]' matches_all.json > matches_compact.json

          # Build payload with ALL matches
          jq -n --arg url "${SRC_URL:-}" --arg client_id "${CLIENT_ID:-}" \
                --arg audit_type "single" --argjson total "${COUNT:-0}" \
                --slurpfile matches matches_compact.json \
                '{url:$url, client_id:$client_id, audit_type:$audit_type, total_suggestions:$total, matches:$matches[0]}' \
              > detail_payload.json

          # POST (follow /exec -> googleusercontent redirect and keep POST)
          HTTP=$(curl -sS -L --post301 --post302 --post303 -o /tmp/doc_cb_detail.out -w "%{http_code}" \
            -X POST "$DOC_CALLBACK_URL?api_key=$DOC_CALLBACK_KEY" \
            -H 'Content-Type: application/json' \
            -H "x-api-key: $DOC_CALLBACK_KEY" \
            --data-binary @detail_payload.json)

          echo "Detail callback HTTP: $HTTP"
          if [ "$HTTP" -lt 200 ] || [ "$HTTP" -ge 300 ]; then
            echo "::error::Detail Doc callback failed (HTTP $HTTP). Response:"
            sed -n '1,200p' /tmp/doc_cb_detail.out
            exit 1
          fi
          echo "Detail Doc callback OK:"
          sed -n '1,200p' /tmp/doc_cb_detail.out

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: grammar-report
          path: |
            doc_full.txt
            chunks/**
            reports/**
            matches_all.json
            matches_compact.json
            detail_payload.json
            report.md
