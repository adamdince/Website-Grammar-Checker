name: Website Grammar Check (GPT, your prompt, parallelized)

on:
  repository_dispatch:
    types: [grammar-check]
  workflow_dispatch:
    inputs:
      url:
        description: "URL to check (optional if payload supplies it)"
        required: false
        type: string
      text:
        description: "Raw text to check (optional)"
        required: false
        type: string

permissions:
  contents: read
  issues: write

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install tools
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y jq lynx perl

      - name: Extract payload and build FULL text
        id: build
        run: |
          set -euo pipefail
          URL=$(jq -r '.client_payload.url // empty' "$GITHUB_EVENT_PATH")
          TEXT=$(jq -r '.client_payload.text // empty' "$GITHUB_EVENT_PATH")
          CID=$(jq -r '.client_payload.client_id // empty' "$GITHUB_EVENT_PATH")
          if [ -z "$URL" ];  then URL="${{ github.event.inputs.url }}";  fi
          if [ -z "$TEXT" ]; then TEXT="${{ github.event.inputs.text }}"; fi

          echo "SRC_URL=$URL"   >> $GITHUB_ENV
          echo "CLIENT_ID=$CID" >> $GITHUB_ENV

          if [ -n "$URL" ]; then
            echo "Fetching $URL"
            curl -fsSL -H "User-Agent: Mozilla/5.0" "$URL" -o page.html
            lynx -dump -nolist page.html > doc_full.txt
          else
            printf "%s" "$TEXT" > doc_full.txt
          fi

          if [ ! -s doc_full.txt ]; then
            echo "::error::No content to analyze (neither URL nor text)"
            exit 1
          fi

          BYTES=$(wc -c < doc_full.txt)
          echo "FULL_BYTES=$BYTES" >> $GITHUB_ENV
          echo "Built doc_full.txt ($BYTES bytes)"

      - name: Chunk long text (~15 KB per chunk)
        run: |
          set -euo pipefail
          rm -rf chunks reports
          mkdir -p chunks reports
          split -b 15000 -d -a 3 doc_full.txt chunks/chunk_
          COUNT=$(ls chunks | wc -l | tr -d ' ')
          echo "CHUNK_COUNT=$COUNT" >> $GITHUB_ENV
          echo "Created $COUNT chunk(s)"

      # >>> The only change vs your working file: this step is now parallel (2 at a time)
      - name: Run GPT proofreading on all chunks (primary gpt-5, fallback gpt-4o) — PARALLEL
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: ${{ vars.OPENAI_MODEL }}   # optional override
        run: |
          set -euo pipefail
          if [ -z "${OPENAI_API_KEY:-}" ]; then
            echo "::error::OPENAI_API_KEY secret is not set"
            exit 1
          fi

          PRIMARY_MODEL="${OPENAI_MODEL:-gpt-5}"
          FALLBACK_MODEL="gpt-4o"

          export OPENAI_API_KEY PRIMARY_MODEL FALLBACK_MODEL
          mkdir -p reports

          # Process chunks in parallel (2 workers). Adjust -P if you want more/fewer.
          ls chunks | sort | xargs -I{} -P 2 bash -c '
            set -euo pipefail
            f="$1"
            fp="chunks/$1"
            out="out_${1}.json"
            rep="reports/$1.json"

            echo "Checking $fp (primary $PRIMARY_MODEL; fallback $FALLBACK_MODEL)"

            build_req() {
              MODEL="$1"
              jq -n --arg model "$MODEL" --rawfile TEXT "$fp" '"'"'{
                model: $model,
                response_format: { "type": "json_object" },
                messages: [
                  {
                    "role":"system",
                    "content":"You are a strict copy editor. Given TEXT, identify EVERY spelling, grammar and punctuation mistake. Ignore double spacing. Return ONLY valid JSON in the following format:\n\n{\n  \"matches\": [\n    {\n      \"rule\": \"Spelling|Grammar|Punctuation\",\n      \"message\": \"What is wrong\",\n      \"context\": \"Short snippet around the error\",\n      \"suggestion\": \"Best single replacement or null\"\n    }\n  ]\n}\n\n- \"rule\" must be one of: \"Spelling\", \"Grammar\", or \"Punctuation\".\n- \"message\" should briefly explain the issue.\n- \"context\" should contain just enough surrounding text to locate the error.\n- \"suggestion\" should contain the corrected text, or null if no single replacement applies.\n- Do not output prose, explanations, or text outside of JSON."
                  },
                  { "role":"user", "content": ("TEXT:\n\n" + $TEXT) }
                ]
              }'"'"'
            }

            # ----- PRIMARY -----
            build_req "$PRIMARY_MODEL" > req.json
            HTTP=$(curl -sS -o "$out" -w "%{http_code}" \
              -X POST https://api.openai.com/v1/chat/completions \
              -H "Authorization: Bearer ${OPENAI_API_KEY}" \
              -H "Content-Type: application/json" \
              --data-binary @req.json)

            # If primary fails for model-availability or model-unsupported, try fallback once
            if [ "$HTTP" -ne 200 ]; then
              ERR=$(jq -r ".error.message // empty" "$out" 2>/dev/null || true)
              TYP=$(jq -r ".error.type // empty" "$out" 2>/dev/null || true)
              echo "::warning::OpenAI $HTTP on $fp using $PRIMARY_MODEL ($TYP) $ERR"
              if echo "$ERR $TYP" | grep -qiE "model|not.?found|does.?not.?exist|unsupported|unknown|deprecat"; then
                # ----- FALLBACK -----
                build_req "$FALLBACK_MODEL" > req.json
                HTTP=$(curl -sS -o "$out" -w "%{http_code}" \
                  -X POST https://api.openai.com/v1/chat/completions \
                  -H "Authorization: Bearer ${OPENAI_API_KEY}" \
                  -H "Content-Type: application/json" \
                  --data-binary @req.json)
              fi
            fi

            if [ "$HTTP" -ne 200 ]; then
              echo "::warning::Model returned $HTTP for $fp after fallback; using empty matches"
              echo "{\"matches\":[]}" > "$rep"
              exit 0
            fi

            # Extract JSON; strip any code fences; validate
            jq -r ".choices[0].message.content" "$out" > "$rep" || true
            perl -0777 -pe '"'"'s/```(?:json)?\s*|\s*```//g'"'"' -i "$rep" || true
            if ! jq -e . "$rep" >/dev/null 2>&1; then
              echo "::warning::Non-JSON from model for $fp (using empty matches)"
              echo "{\"matches\":[]}" > "$rep"
            fi
          ' _ {}

          # Aggregate all matches across chunks (same as your working file)
          jq -s '[.[] | .matches] | flatten' reports/*.json > matches_all.json
          COUNT=$(jq 'length' matches_all.json)
          echo "COUNT=$COUNT" >> $GITHUB_ENV
          echo "Aggregated $COUNT match(es)"

      - name: Build Markdown report
        run: |
          set -euo pipefail
          test -f matches_all.json || echo '[]' > matches_all.json
          {
            echo "# Grammar Report (GPT)"
            if [ -n "${SRC_URL}"   ]; then echo "**URL:** ${SRC_URL}  "; fi
            if [ -n "${CLIENT_ID}" ]; then echo "**Client ID:** ${CLIENT_ID}  "; fi
            echo "**Bytes scanned (full):** ${FULL_BYTES}  "
            echo "**Chunks:** ${CHUNK_COUNT}  "
            echo "**Issues found:** ${COUNT}"
            echo
            echo "## Sample findings (first 100)"
            jq -r '
              .[0:100][] |
              "- **\(.rule // "")**: \(.message // "")
                 - Context: \"\(.context // "")\"
                 - Suggestion: \((.suggestion // "—"))"
            ' matches_all.json
          } > report.md
          echo "Report written to report.md"

      - name: Create issue with report
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const url = process.env.SRC_URL || '(manual input)';
            const title = `Grammar report – ${url} – ${new Date().toISOString().slice(0,19)}Z`;
            const body  = fs.readFileSync('report.md','utf8');
            const labels = ['grammar-report','gpt'];
            const { data: issue } = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title, body, labels
            });
            core.info(`Created issue #${issue.number}`);

      # === keep these two steps EXACTLY as in your working file ===
      - name: Resolve Apps Script Web App redirect (for POST)
        env:
          DOC_CALLBACK_URL: ${{ secrets.DOC_CALLBACK_URL }}
        run: |
          set -euo pipefail
          if [ -z "${DOC_CALLBACK_URL:-}" ]; then
            echo "::notice::No DOC_CALLBACK_URL configured; skipping resolve"
            exit 0
          fi
          if echo "${DOC_CALLBACK_URL}" | grep -qi 'docs.google.com'; then
            echo "::error::DOC_CALLBACK_URL points to a Google Doc. Use the Web App /exec URL from Apps Script deployments."
            exit 1
          fi
          LOC=$(curl -sS -I "$DOC_CALLBACK_URL" | tr -d '\r' | awk 'tolower($1)=="location:"{print $2}' | tail -1 || true)
          if [ -n "$LOC" ]; then
            echo "CB_URL=$LOC" >> $GITHUB_ENV
            echo "Resolved callback URL: $LOC"
          else
            echo "CB_URL=$DOC_CALLBACK_URL" >> $GITHUB_ENV
            echo "Using original callback URL (no redirect exposed)."
          fi

      - name: Post ALL findings to Google Doc (optional)
        env:
          CB_URL: ${{ env.CB_URL }}
          DOC_CALLBACK_KEY: ${{ secrets.DOC_CALLBACK_KEY }}
          SRC_URL:   ${{ env.SRC_URL }}
          CLIENT_ID: ${{ env.CLIENT_ID }}
          COUNT:     ${{ env.COUNT }}
        run: |
          set -euo pipefail
          if [ -z "${CB_URL:-}" ] || [ -z "${DOC_CALLBACK_KEY:-}" ]; then
            echo "Doc callback secrets not set; skipping."
            exit 0
          fi

          jq '[ .[] | {
                rule:(.rule // null),
                message:(.message // null),
                context:(.context // null),
                suggestion:(.suggestion // null)
              } ]' matches_all.json > matches_compact.json

          jq -n --arg url "${SRC_URL:-}" --arg client_id "${CLIENT_ID:-}" \
                --arg audit_type "single" --argjson total "${COUNT:-0}" \
                --slurpfile matches matches_compact.json \
                '{url:$url, client_id:$client_id, audit_type:$audit_type, total_suggestions:$total, matches:$matches[0]}' \
              > detail_payload.json

          HTTP=$(curl -sS -o /tmp/doc_cb_detail.out -w "%{http_code}" \
            -X POST "$CB_URL?api_key=$DOC_CALLBACK_KEY" \
            -H 'Content-Type: application/json' \
            -H "x-api-key: $DOC_CALLBACK_KEY" \
            --data-binary @detail_payload.json)

          echo "Detail callback HTTP: $HTTP"
          # treat 3xx as success; only fail on 4xx / 5xx
          if [ "$HTTP" -lt 200 ] || [ "$HTTP" -ge 400 ]; then
            echo "::error::Detail Doc callback failed (HTTP $HTTP). Response:"
            sed -n '1,200p' /tmp/doc_cb_detail.out
            exit 1
          fi
          echo "Detail Doc callback accepted (HTTP $HTTP):"
          sed -n '1,120p' /tmp/doc_cb_detail.out

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: grammar-report
          path: |
            doc_full.txt
            chunks/**
            reports/**
            matches_all.json
            report.md
